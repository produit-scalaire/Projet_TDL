{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c17d16c3",
      "metadata": {},
      "source": [
        "Implémentation du papier de recherche \"(S)GD over Diagonal Linear Networks:\n",
        "Implicit Bias, Large Stepsizes and Edge of Stability\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "50e647b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1fb7760",
      "metadata": {},
      "source": [
        "# Données synthétiques"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "504199f3",
      "metadata": {},
      "source": [
        "On génère les données synthétiques pour avoir un $\\beta_{sparse}$ à support non nul sur k composantes et nul sur le reste$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ef303a0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_data(n, d, k, sigma=0.0):\n",
        "    \"\"\"\n",
        "    Génère des données synthétiques pour la régression l1.\n",
        "    n: nombre d'échantillons\n",
        "    d: dimension des données\n",
        "    k: sparsité (nombre de composantes non nulles dans w*)\n",
        "    sigma: bruit\n",
        "    \"\"\"\n",
        "    X = torch.randn(n, d)\n",
        "    \n",
        "    w_star = torch.zeros(d, 1)\n",
        "    indices = torch.randperm(d)[:k]\n",
        "    w_star[indices] = torch.randn(k, 1) \n",
        "    \n",
        "    y = X @ w_star + sigma * torch.randn(n, 1)\n",
        "    \n",
        "    return X, y, w_star\n",
        "\n",
        "# Paramètres standards du papier (ex: d=100, n=40, k=3)\n",
        "n, d, k = 40, 100, 3\n",
        "X, y, w_star = generate_data(n, d, k)\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(X, y)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd6aac75",
      "metadata": {},
      "source": [
        "# Initialisation de la classe du Diagonal Linear Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "797894d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "class DLN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, alpha = 1.0, uniform = True):\n",
        "        super(DLN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "        self.alpha = alpha\n",
        "        self.uniform = uniform\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "\n",
        "        nn.init.zeros_(self.fc1.weight)\n",
        "        nn.init.zeros_(self.fc2.weight)\n",
        "        if self.fc1.bias is not None: nn.init.zeros_(self.fc1.bias)\n",
        "        if self.fc2.bias is not None: nn.init.zeros_(self.fc2.bias)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            min_dim = min(self.fc1.in_features, self.fc1.out_features)\n",
        "\n",
        "            if self.uniform:\n",
        "                vals = torch.full((min_dim,), self.alpha)\n",
        "            \n",
        "            else:\n",
        "                vals = torch.rand(min_dim) * 2 * self.alpha\n",
        "            \n",
        "            indices = torch.arange(min_dim)\n",
        "            self.fc1.weight[indices, indices] = vals\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78942790",
      "metadata": {},
      "source": [
        "# Fonction d'entrainement du DLN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca16e9d0",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0a253384",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_dln(model, X, y, lr, epochs, mode='gd', batch_size=None):\n",
        "    criterion = nn.MSELoss()\n",
        "    \n",
        "    if mode == 'sgd' and batch_size is None:\n",
        "        batch_size = 1\n",
        "        \n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    \n",
        "    losses = []\n",
        "    \n",
        "    if mode == 'gd':\n",
        "        data_loader = [(X, y)] \n",
        "    else:\n",
        "        dataset = torch.utils.data.TensorDataset(X, y)\n",
        "        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "        \n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for batch_X, batch_y in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(batch_X)\n",
        "            loss = criterion(output, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item() * batch_X.size(0)\n",
        "            \n",
        "        losses.append(epoch_loss / X.size(0))\n",
        "        \n",
        "    return losses"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
